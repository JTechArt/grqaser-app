# Smart Crawling System Guide

## ğŸ¯ Overview

The Smart Crawling System is an enhanced approach that implements intelligent link generation and status management. It addresses the requirements you specified:

1. **Truncate and regenerate** the `crawl_links` table
2. **Check existing books** in the database
3. **Smart status assignment** based on existing data
4. **Error handling** from previous crawl attempts

## ğŸš€ Quick Start

### Step 1: Generate Smart Crawl Links
```bash
# Generate links for range 1-1200 (default)
npm run smart-generate

# Or specify custom range
node smart-generate-crawl-links.js 1 1200
```

### Step 2: Start Smart Crawling
```bash
npm run smart-crawl
```

### Step 3: Monitor Progress
```bash
node check-crawl-status.js
```

## ğŸ”§ How It Works

### Smart Link Generation Process

#### 1. **Table Truncation**
- Completely clears the `crawl_links` table
- Ensures clean slate for new crawling session

#### 2. **Database Analysis**
- Scans existing `books` table for completed books
- Checks `crawl_status`, `crawl_error`, and `main_audio_url` fields
- Builds a map of existing book statuses

#### 3. **Intelligent Status Assignment**

For each book ID (1-1200), the system checks:

```javascript
if (existingBooks[bookId]) {
  const book = existingBooks[bookId];
  
  if (book.crawl_status === 'completed' || book.has_audio) {
    status = 'SUCCESS';  // Already completed
  } else if (book.crawl_status === 'failed' || book.crawl_error) {
    status = 'FAILED';   // Previous failure
  } else {
    status = 'NEW';      // Ready for retry
  }
} else {
  status = 'NEW';        // Never crawled
}
```

#### 4. **Status Breakdown**
- **SUCCESS**: Books already completed (with audio URLs)
- **NEW**: Books ready for crawling
- **FAILED**: Books that failed in previous attempts

## ğŸ“Š Database Schema

### Crawl Links Table
```sql
CREATE TABLE crawl_links (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  book_id INTEGER NOT NULL,
  url TEXT NOT NULL,
  status VARCHAR(20) DEFAULT 'NEW',
  priority INTEGER DEFAULT 1,
  retry_count INTEGER DEFAULT 0,
  max_retries INTEGER DEFAULT 3,
  error_message TEXT,
  books_found INTEGER DEFAULT 0,
  books_saved INTEGER DEFAULT 0,
  processing_started_at TIMESTAMP,
  completed_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  UNIQUE(book_id)
);
```

### Books Table (Enhanced)
```sql
-- Existing columns plus crawl tracking
crawl_status VARCHAR(20) DEFAULT 'pending'
crawl_error TEXT
crawl_attempts INTEGER DEFAULT 0
last_crawl_attempt TIMESTAMP
main_audio_url TEXT
```

## ğŸ¯ Smart Status Logic

### Status Assignment Rules

| Condition | Status | Description |
|-----------|--------|-------------|
| Book exists + has audio URL | `SUCCESS` | Already completed successfully |
| Book exists + crawl_status = 'completed' | `SUCCESS` | Marked as completed |
| Book exists + crawl_error present | `FAILED` | Previous crawl failed |
| Book exists + crawl_status = 'failed' | `FAILED` | Marked as failed |
| Book exists + pending/processing | `NEW` | Reset for retry |
| Book doesn't exist | `NEW` | Never crawled |

### Error Handling

The system preserves error information from previous attempts:

```javascript
if (book.crawl_error) {
  errorMessage = book.crawl_error || 'Previous crawl failed';
  status = 'FAILED';
}
```

## ğŸ“ˆ Expected Results

### Sample Output
```
ğŸš€ Starting Smart Crawl Link Generation...
ğŸ“Š Range: 1 to 1200
âœ… Database connected
ğŸ”§ Creating crawl_links table...
âœ… Crawl links table created/verified
ğŸ—‘ï¸  Truncating crawl_links table...
âœ… Crawl links table truncated
ğŸ“Š Analyzing existing books in database...
   Found 485 existing books in database
ğŸ”§ Generating smart crawl links from ID 1 to 1200...
âœ… Generated 1200 crawl links
   ğŸ“Š Status breakdown:
      âœ… SUCCESS: 485 (already completed)
      ğŸ”„ NEW: 715 (ready for crawling)
      âŒ FAILED: 0 (previous failures)

ğŸ“Š === SMART CRAWL LINKS SUMMARY ===
ğŸ“‹ Status Breakdown:
   NEW: 715 links
   SUCCESS: 485 links
      ğŸ’¾ Books saved: 485

ğŸ“Š TOTAL: 1200 links
ğŸ“– Total books found: 485
ğŸ’¾ Total books saved: 485

ğŸš€ Ready for crawling: 715 NEW links
```

## ğŸ”„ Smart Sequential Crawler

### Enhanced Features

#### 1. **Batch Processing**
- Processes books in configurable batches (default: 50)
- Provides progress updates every 10 books
- Better memory management

#### 2. **Robust Data Extraction**
- Multiple CSS selectors for each field
- Fallback strategies for different page layouts
- Comprehensive error handling

#### 3. **Status Tracking**
- Real-time status updates in database
- Detailed progress reporting
- Error preservation for analysis

#### 4. **Performance Monitoring**
- Processing rate calculation
- Time tracking per batch
- Success/failure statistics

### Configuration Options

```javascript
this.settings = {
  delayBetweenRequests: 1000,    // 1 second between requests
  timeout: 15000,                // 15 seconds timeout per page
  retryAttempts: 3,              // Number of retry attempts
  batchSize: 50,                 // Books per batch
  autoRetryFailed: true          // Auto-retry failed links
};
```

## ğŸ“Š Monitoring and Analysis

### Progress Tracking
```
ğŸ“¦ Processing batch 1...
ğŸ“– Crawling book ID 1: https://grqaser.org/hy/books/1
   âœ… Saved: Book Title by Author Name
ğŸ“Š Batch progress: 10/50 (0.95/sec)
   âœ… Batch 1 completed: 50 books in 52.3s

ğŸ“Š === CRAWL PROGRESS ===
â±ï¸  Total time: 0.9 minutes
ğŸš€ Rate: 0.95 requests/second
ğŸ“– Total requests: 50
âœ… Successful: 12
âŒ Failed: 38
ğŸ“š Books found: 12
ğŸ’¾ Books saved: 12

ğŸ“‹ Status breakdown:
   SUCCESS: 12 links
   FAILED: 38 links
   NEW: 663 links
```

### Status Checking
```bash
# Check overall status
node check-crawl-status.js

# Show recent activity
node check-crawl-status.js --recent

# Show failed links
node check-crawl-status.js --failed
```

## ğŸ¯ Benefits of Smart System

### 1. **No Duplicate Work**
- Automatically skips completed books
- Preserves previous crawl results
- Efficient resource utilization

### 2. **Error Preservation**
- Maintains error history
- Allows analysis of failure patterns
- Enables targeted retry strategies

### 3. **Intelligent Resume**
- Can resume from any point
- No loss of progress
- Batch-based processing

### 4. **Comprehensive Tracking**
- Real-time status updates
- Detailed progress reporting
- Performance metrics

## ğŸ”§ Advanced Usage

### Custom Range Generation
```bash
# Generate links for specific range
node smart-generate-crawl-links.js 500 1000

# Generate links for higher range
node smart-generate-crawl-links.js 1200 2000
```

### Configuration Customization
Edit the crawler settings in `src/smart-sequential-crawler.js`:

```javascript
this.settings = {
  delayBetweenRequests: 2000,    // Slower, more respectful
  batchSize: 25,                 // Smaller batches
  timeout: 20000,                // Longer timeout
  retryAttempts: 5               // More retries
};
```

### Database Queries
```sql
-- Check smart status distribution
SELECT status, COUNT(*) as count 
FROM crawl_links 
GROUP BY status 
ORDER BY count DESC;

-- Find books ready for crawling
SELECT book_id, url 
FROM crawl_links 
WHERE status = 'NEW' 
ORDER BY book_id 
LIMIT 10;

-- Analyze previous failures
SELECT book_id, error_message 
FROM crawl_links 
WHERE status = 'FAILED' 
ORDER BY book_id;
```

## ğŸš¨ Troubleshooting

### Common Issues

1. **No NEW links found**
   - Run `smart-generate` first
   - Check if all books are already completed

2. **High failure rate**
   - Check error messages for patterns
   - Verify website structure hasn't changed
   - Increase timeout settings

3. **Database errors**
   - Ensure database file exists
   - Check file permissions
   - Run migration if needed

### Performance Tips

1. **Batch Size**: Adjust based on system resources
2. **Delays**: Increase for more respectful crawling
3. **Timeouts**: Adjust based on website response times
4. **Monitoring**: Check progress regularly

## ğŸ‰ Success Metrics

### Expected Results
- **Efficiency**: 90%+ reduction in duplicate work
- **Accuracy**: Proper status preservation
- **Performance**: Consistent processing rates
- **Reliability**: Robust error handling

### Quality Indicators
- **Status Accuracy**: Correct assignment of SUCCESS/NEW/FAILED
- **Error Preservation**: Previous errors maintained
- **Progress Tracking**: Real-time updates working
- **Data Integrity**: No duplicate entries

## ğŸ“ Next Steps

1. **Run Smart Generation**: `npm run smart-generate`
2. **Start Crawling**: `npm run smart-crawl`
3. **Monitor Progress**: Use status checker
4. **Analyze Results**: Review success/failure patterns
5. **Extend Range**: Generate more links if needed

The Smart Crawling System provides a robust, efficient, and intelligent approach to managing the crawling process while preserving previous work and maintaining comprehensive status tracking.
