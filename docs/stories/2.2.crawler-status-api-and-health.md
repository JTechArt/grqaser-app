# Story 2.2: Crawler status API and health

## Status

Done

## Story

**As an** operator,  
**I want** endpoints for crawler status, URL queue, and logs, plus a health check,  
**so that** I can monitor the pipeline from the admin panel or scripts.

## Acceptance Criteria

1. Crawler status (and optionally URL queue and logs) are exposed via API (e.g., `/api/v1/crawler/status`, `/urls`, `/logs`).
2. `GET /api/v1/health` returns service health and optionally DB connectivity.
3. Configuration (port, DB path, CORS, rate limit, logging) is externalized (e.g., env or config file).

## Tasks / Subtasks

- [x] Task 1: Crawler status and queue/logs API (AC: 1)
  - [x] Expose crawler status (and optionally URL queue and logs) via API, e.g. `/api/v1/crawler/status`, `/api/v1/crawler/urls`, `/api/v1/crawler/logs` ([Source: docs/architecture/database-viewer-api-and-deployment.md]).
  - [x] Read from crawler-produced tables (url_queue, crawl_logs) or log files; read-only.
  - [x] Unit/integration tests for crawler routes.
- [x] Task 2: Health endpoint (AC: 2)
  - [x] Implement `GET /api/v1/health` returning service health and DB connectivity ([Source: docs/architecture/database-viewer-api-and-deployment.md], [Source: docs/architecture/coding-standards.md]).
  - [x] Test health returns 200 when DB is reachable; appropriate status when not.
- [x] Task 3: Configuration externalization (AC: 3)
  - [x] Externalize port, DB path, CORS, rate limit, logging (env or config file, e.g. `database-viewer/src/config/config.js`) ([Source: docs/architecture/database-viewer-api-and-deployment.md], [Source: docs/architecture/coding-standards.md]).
  - [x] Document or example env; no hardcoded paths or secrets.

## Dev Notes

### Previous Story Insights

Story 2.1 delivers books and stats API. This story adds crawler monitoring and health; config must be externalized for deployment.

### Data Models

- **URL queue** (crawler): url, url_type, priority, status, retry_count, etc. **Crawl logs:** level, message, book_id, url, error_details ([Source: docs/architecture/data-models-and-schema.md]). Exposed read-only by database-viewer.

### API Specifications

- **Crawler:** `/api/v1/crawler/status`, `/urls`, `/logs`. **Health:** `GET /api/v1/health` ([Source: docs/architecture/database-viewer-api-and-deployment.md]).

### File Locations

- **Entry:** `database-viewer/src/server.js`. **Config:** `database-viewer/src/config/config.js`. **Routes:** e.g. `database-viewer/src/routes/crawler.js`. **Models:** `database-viewer/src/models/database.js` ([Source: docs/architecture/database-viewer-api-and-deployment.md]).

### Technical Constraints

- Config over hardcoding; health must reflect DB connectivity ([Source: docs/architecture/coding-standards.md]).

### Testing

- Unit tests for crawler and health handlers; integration tests with DB ([Source: docs/architecture/testing-and-deployment-strategy.md]). Run: `npm test` from `database-viewer/`.

## Change Log

| Date       | Version | Description                    | Author       |
|-----------|---------|--------------------------------|--------------|
| 2025-02-14 | 1.0     | Story created from Epic 2     | Scrum Master |
| 2025-02-16 | 1.1     | Implemented AC1–AC3; health DB check; tests; .env.example | Dev Agent    |
| 2025-02-16 | 1.2     | QA follow-up: single shared DB for crawler routes (inject from server) | Dev Agent    |

## Dev Agent Record

### Agent Model Used

—

### Debug Log References

—

### Completion Notes List

- Health endpoint now checks DB with `db.get('SELECT 1')`; returns 200 with `database: 'connected'` when reachable, 503 with `database: 'disconnected'` when not (AC2).
- Config already externalized; added rate limit env vars (`RATE_LIMIT_WINDOW_MS`, `RATE_LIMIT_MAX`) and `.env.example` (AC3).
- Crawler routes `/status`, `/urls`, `/logs` were already implemented; added Jest + Supertest tests (health + crawler) and test DB setup (AC1).
- Server refactored for test: skip listen when `NODE_ENV=test`, export `db` and `startServer` for tests.
- QA follow-up: crawler routes now use a single shared DB instance injected from server (`createCrawlerRouter(db)`); removed second `Database()` and `ensureConnection()` from `routes/crawler.js`.

### File List

- database-viewer/src/server.js (modified)
- database-viewer/src/config/config.js (modified)
- database-viewer/.env.example (new)
- database-viewer/jest.config.js (new)
- database-viewer/tests/create-test-db.js (new)
- database-viewer/tests/setup.js (new)
- database-viewer/tests/health.test.js (new)
- database-viewer/tests/crawler.test.js (new)
- database-viewer/src/routes/crawler.js (modified — shared DB injection)

## QA Results

### Review Date: 2026-02-16

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

Implementation meets all acceptance criteria. Crawler routes (`/status`, `/urls`, `/logs`) and `GET /api/v1/health` are implemented with consistent response shape; health correctly returns 200 with `database: 'connected'` when DB is reachable and 503 with `database: 'disconnected'` when not. Configuration is externalized in `config.js` with env vars; `.env.example` documents port, DB path, CORS, rate limit, and logging. Server is refactored for testability (skip listen when `NODE_ENV=test`, exported `app`, `db`, `startServer`). Test suite uses a minimal test DB and covers health (including disconnected case) and all three crawler endpoints with query params.

### Refactoring Performed

None. No code changes were required for this review.

### Compliance Check

- Coding Standards: ✓ Config over hardcoding; no hardcoded secrets; consistent error payloads.
- Project Structure: ✓ Routes in `database-viewer/src/routes/`, config in `database-viewer/src/config/`, tests in `database-viewer/tests/`.
- Testing Strategy: ✓ Unit/integration tests for health and crawler handlers with DB; run via `npm test` from `database-viewer/`.
- All ACs Met: ✓ AC1 (crawler status/urls/logs API), AC2 (health with DB check), AC3 (config externalized).

### Improvements Checklist

- [x] All acceptance criteria verified against implementation and tests
- [x] Shared db instance injected into crawler routes (follow-up applied by dev)

### Security Review

No concerns. Read-only admin API; rate limiting and CORS configured via env; no credentials in code.

### Performance Considerations

None. Read-only queries; pagination on logs; rate limit applied to `/api/`.

### Files Modified During Review

None.

### Gate Status

Gate: PASS → docs/qa/gates/2.2-crawler-status-api-and-health.yml

### Recommended Status

✓ Ready for Done (story owner decides final status).

---

### Review Date: 2026-02-16 (re-review after follow-up)

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

Re-review after dev implemented the optional follow-up: **shared DB injection for crawler routes**. Crawler router now exports `createCrawlerRouter(db)` and receives the single `db` instance from `server.js` via `crawlerRoutes(db)`. No second `Database()` in crawler routes; one connection shared for health and crawler endpoints. All 8 tests (health + crawler) pass.

### Refactoring Performed

None. Follow-up was implemented by dev; QA verified only.

### Compliance Check

- Coding Standards: ✓ Unchanged; dependency injection preserves existing patterns.
- Project Structure: ✓ Unchanged.
- Testing Strategy: ✓ All story 2.2 tests pass.
- All ACs Met: ✓ Unchanged.

### Improvements Checklist

- [x] Future recommendation (shared db in crawler routes) implemented and verified.

### Gate Status

Gate: PASS → docs/qa/gates/2.2-crawler-status-api-and-health.yml (updated; future recommendation removed).

### Recommended Status

✓ Ready for Done.

